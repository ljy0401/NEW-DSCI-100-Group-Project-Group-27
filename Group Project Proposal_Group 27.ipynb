{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSCI 100 Group Project Proposal - Group 27\n",
    "\n",
    "Raisin Dataset - Classification For Different Types of Raisin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.2     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.0.3     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.2     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "Warning message:\n",
      "“package ‘ggplot2’ was built under R version 4.0.1”\n",
      "Warning message:\n",
      "“package ‘tibble’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘tidyr’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘dplyr’ was built under R version 4.0.2”\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "Warning message:\n",
      "“package ‘tidymodels’ was built under R version 4.0.2”\n"
     ]
    }
   ],
   "source": [
    "### Run this cell before continuing.\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(gridExtra)\n",
    "library(repr)\n",
    "library(cowplot)\n",
    "set.seed(27)\n",
    "options(repr.matrix.max.rows = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚫ Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚫ Preliminary exploratory data analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in read_csv(url) %>% select(Area, ConvexArea, Perimeter, Class): could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in read_csv(url) %>% select(Area, ConvexArea, Perimeter, Class): could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "url <- \"https://raw.githubusercontent.com/ljy0401/DSCI-100-Group-Project-Group-27/main/raisin_dataset.csv\"\n",
    "raisin_data <- read_csv(url) %>% select(Area, ConvexArea, Perimeter, Class)\n",
    "raisin_his <- raisin_data %>% pivot_longer(cols=Area:Perimeter, names_to= \"Predictor\", values_to= \"Measurment\")\n",
    "raisin_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚫ Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the .csv dataset file into R, we first select the perimeter, area, and convex area columns as our predictor variables and the class column as our categorical variable (target). In order to keep the computation time and process manageable and neglect variables that do not do well in classifying two types of raisin (two classes have large overlapping areas), we will drop other columns at this point. In order to actually make predictions for new observations, we will use the K-nearest neighbors classification algorithm. Next, we plan to randomly split the whole dataset into a training dataset with 75% and a testing dataset with 25%. We then need to create the KNN model and the recipe. It is important to notice that both classes have a relatively balancing amount of observations, but the scale of each predictor varies significantly. In order to avoid the prediction being dominated by one variable, we will add scale and center steps to our recipe. Besides, instead of randomly assigning the K-neighbors value, we decide to perform cross-validation and tune the classifier to find the best K which gives us the highest accuracy. Finally, we can add the recipe and tuned model to the workflow and fit it to our training dataset. Then we can use it to predict the class of our testing dataset observations and compute the true accuracy of these predictions.\n",
    "\n",
    "To visualize the prediction, we would have to limit the predictors to two variables since a 3-dimension plot is generally not recommended in this course. We can create a colored prediction map (scatter plot) by creating a grid of synthetic new observations, with one predictor on x-axis and the other on y-axis, using colors to distinguish different types of raisin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚫ Expected outcomes and significance:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
